{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for i in range(1,4001):\n",
    "    num = str(i).zfill(4)\n",
    "    img = cv2.imread('newimg/img'+ num +'.jpg')\n",
    "    img = cv2.resize(img, (100,100))\n",
    "    img = img/255\n",
    "    imgs.append(img)\n",
    "imgs = np.array(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S_R.AliEN\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3441: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('labels.txt',' ',header=None)\n",
    "y = y.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 100 100 3\n"
     ]
    }
   ],
   "source": [
    "num_samples = imgs.shape[0]  # number of images\n",
    "height = imgs.shape[1]  # height of each image\n",
    "width = imgs.shape[2]  # width of each image\n",
    "channels = imgs.shape[3]  # number of color channels\n",
    "print(num_samples,height,width,channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No reshape is needed but in that case we use this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs = imgs.reshape((num_samples, height, width, channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data into three group : train 80%, test 20%, validation 20% of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs, y,\n",
    "    test_size=0.2, shuffle = True, random_state = 20)\n",
    "\n",
    "# Use the same function above for the validation set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
    "    test_size=0.2, random_state= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using augmentation for preventing overfiting and more powerful model, It rotate, shift, zoom and flip horizontal the photos randomly\n",
    "- Using preprocessing tool available in keras -> imagedatagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = ImageDataGenerator(\n",
    "    rotation_range=5,  # randomly rotate images by up to 5 degrees\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally by up to 10%\n",
    "    height_shift_range=0.1,  # randomly shift images vertically by up to 10%\n",
    "    zoom_range=0.1,  # randomly zoom in and out on images\n",
    "    horizontal_flip=True,  # randomly flip images horizontally\n",
    "    fill_mode='nearest'  # fill in missing pixels with nearest neighbor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding layers and building CNN model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[100, 100, 3]))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit with augmentation and 40 epochs and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "80/80 [==============================] - 33s 384ms/step - loss: 0.6894 - accuracy: 0.5535 - val_loss: 0.6626 - val_accuracy: 0.6297\n",
      "Epoch 2/40\n",
      "80/80 [==============================] - 35s 439ms/step - loss: 0.6671 - accuracy: 0.6109 - val_loss: 0.6381 - val_accuracy: 0.6469\n",
      "Epoch 3/40\n",
      "80/80 [==============================] - 23s 291ms/step - loss: 0.6067 - accuracy: 0.6789 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 4/40\n",
      "80/80 [==============================] - 24s 301ms/step - loss: 0.5427 - accuracy: 0.7363 - val_loss: 0.4691 - val_accuracy: 0.7969\n",
      "Epoch 5/40\n",
      "80/80 [==============================] - 26s 322ms/step - loss: 0.4832 - accuracy: 0.7793 - val_loss: 0.4137 - val_accuracy: 0.8406\n",
      "Epoch 6/40\n",
      "80/80 [==============================] - 29s 363ms/step - loss: 0.4341 - accuracy: 0.8129 - val_loss: 0.3731 - val_accuracy: 0.8469\n",
      "Epoch 7/40\n",
      "80/80 [==============================] - 27s 336ms/step - loss: 0.4126 - accuracy: 0.8234 - val_loss: 0.3189 - val_accuracy: 0.8781\n",
      "Epoch 8/40\n",
      "80/80 [==============================] - 32s 395ms/step - loss: 0.4032 - accuracy: 0.8363 - val_loss: 0.3381 - val_accuracy: 0.8625\n",
      "Epoch 9/40\n",
      "80/80 [==============================] - 25s 317ms/step - loss: 0.3725 - accuracy: 0.8352 - val_loss: 0.3275 - val_accuracy: 0.8656\n",
      "Epoch 10/40\n",
      "80/80 [==============================] - 24s 303ms/step - loss: 0.3797 - accuracy: 0.8410 - val_loss: 0.2764 - val_accuracy: 0.8984\n",
      "Epoch 11/40\n",
      "80/80 [==============================] - 25s 315ms/step - loss: 0.3452 - accuracy: 0.8539 - val_loss: 0.2839 - val_accuracy: 0.8969\n",
      "Epoch 12/40\n",
      "80/80 [==============================] - 25s 310ms/step - loss: 0.3363 - accuracy: 0.8586 - val_loss: 0.2684 - val_accuracy: 0.9031\n",
      "Epoch 13/40\n",
      "80/80 [==============================] - 25s 308ms/step - loss: 0.3322 - accuracy: 0.8641 - val_loss: 0.2633 - val_accuracy: 0.9031\n",
      "Epoch 14/40\n",
      "80/80 [==============================] - 24s 294ms/step - loss: 0.3236 - accuracy: 0.8648 - val_loss: 0.2534 - val_accuracy: 0.9172\n",
      "Epoch 15/40\n",
      "80/80 [==============================] - 23s 288ms/step - loss: 0.3253 - accuracy: 0.8637 - val_loss: 0.2642 - val_accuracy: 0.8984\n",
      "Epoch 16/40\n",
      "80/80 [==============================] - 24s 297ms/step - loss: 0.2989 - accuracy: 0.8770 - val_loss: 0.2509 - val_accuracy: 0.9094\n",
      "Epoch 17/40\n",
      "80/80 [==============================] - 24s 294ms/step - loss: 0.2919 - accuracy: 0.8840 - val_loss: 0.2351 - val_accuracy: 0.9203\n",
      "Epoch 18/40\n",
      "80/80 [==============================] - 23s 286ms/step - loss: 0.2871 - accuracy: 0.8801 - val_loss: 0.2240 - val_accuracy: 0.9125\n",
      "Epoch 19/40\n",
      "80/80 [==============================] - 25s 307ms/step - loss: 0.2865 - accuracy: 0.8832 - val_loss: 0.2496 - val_accuracy: 0.8984\n",
      "Epoch 20/40\n",
      "80/80 [==============================] - 24s 300ms/step - loss: 0.2741 - accuracy: 0.8809 - val_loss: 0.2801 - val_accuracy: 0.8984\n",
      "Epoch 21/40\n",
      "80/80 [==============================] - 23s 285ms/step - loss: 0.2741 - accuracy: 0.8902 - val_loss: 0.2203 - val_accuracy: 0.9219\n",
      "Epoch 22/40\n",
      "80/80 [==============================] - 24s 297ms/step - loss: 0.2812 - accuracy: 0.8809 - val_loss: 0.2179 - val_accuracy: 0.9219\n",
      "Epoch 23/40\n",
      "80/80 [==============================] - 23s 290ms/step - loss: 0.2603 - accuracy: 0.8906 - val_loss: 0.2155 - val_accuracy: 0.9250\n",
      "Epoch 24/40\n",
      "80/80 [==============================] - 24s 293ms/step - loss: 0.2554 - accuracy: 0.8977 - val_loss: 0.2158 - val_accuracy: 0.9250\n",
      "Epoch 25/40\n",
      "80/80 [==============================] - 24s 297ms/step - loss: 0.2560 - accuracy: 0.8988 - val_loss: 0.1962 - val_accuracy: 0.9312\n",
      "Epoch 26/40\n",
      "80/80 [==============================] - 24s 304ms/step - loss: 0.2382 - accuracy: 0.8996 - val_loss: 0.2223 - val_accuracy: 0.9250\n",
      "Epoch 27/40\n",
      "80/80 [==============================] - 24s 298ms/step - loss: 0.2264 - accuracy: 0.9047 - val_loss: 0.2309 - val_accuracy: 0.9141\n",
      "Epoch 28/40\n",
      "80/80 [==============================] - 26s 326ms/step - loss: 0.2279 - accuracy: 0.9160 - val_loss: 0.2249 - val_accuracy: 0.9203\n",
      "Epoch 29/40\n",
      "80/80 [==============================] - 27s 337ms/step - loss: 0.2317 - accuracy: 0.9031 - val_loss: 0.2312 - val_accuracy: 0.9203\n",
      "Epoch 30/40\n",
      "80/80 [==============================] - 27s 339ms/step - loss: 0.2290 - accuracy: 0.9008 - val_loss: 0.2042 - val_accuracy: 0.9391\n",
      "Epoch 31/40\n",
      "80/80 [==============================] - 27s 341ms/step - loss: 0.2192 - accuracy: 0.9078 - val_loss: 0.2074 - val_accuracy: 0.9281\n",
      "Epoch 32/40\n",
      "80/80 [==============================] - 28s 350ms/step - loss: 0.2256 - accuracy: 0.9082 - val_loss: 0.1950 - val_accuracy: 0.9359\n",
      "Epoch 33/40\n",
      "80/80 [==============================] - 27s 337ms/step - loss: 0.2198 - accuracy: 0.9113 - val_loss: 0.2032 - val_accuracy: 0.9219\n",
      "Epoch 34/40\n",
      "80/80 [==============================] - 27s 332ms/step - loss: 0.2134 - accuracy: 0.9156 - val_loss: 0.1989 - val_accuracy: 0.9391\n",
      "Epoch 35/40\n",
      "80/80 [==============================] - 27s 337ms/step - loss: 0.2104 - accuracy: 0.9152 - val_loss: 0.1901 - val_accuracy: 0.9344\n",
      "Epoch 36/40\n",
      "80/80 [==============================] - 27s 338ms/step - loss: 0.1997 - accuracy: 0.9160 - val_loss: 0.2243 - val_accuracy: 0.9266\n",
      "Epoch 37/40\n",
      "80/80 [==============================] - 27s 340ms/step - loss: 0.2074 - accuracy: 0.9203 - val_loss: 0.2000 - val_accuracy: 0.9312\n",
      "Epoch 38/40\n",
      "80/80 [==============================] - 29s 365ms/step - loss: 0.2072 - accuracy: 0.9203 - val_loss: 0.1962 - val_accuracy: 0.9344\n",
      "Epoch 39/40\n",
      "80/80 [==============================] - 23s 286ms/step - loss: 0.1941 - accuracy: 0.9246 - val_loss: 0.1990 - val_accuracy: 0.9234\n",
      "Epoch 40/40\n",
      "80/80 [==============================] - 23s 286ms/step - loss: 0.2062 - accuracy: 0.9223 - val_loss: 0.1881 - val_accuracy: 0.9359\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(augmentation.flow(x_train, y_train, batch_size=32), epochs = 40, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1638656   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,695,233\n",
      "Trainable params: 1,695,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with test set, we obtained very good accuracy 93.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 70ms/step - loss: 0.1676 - accuracy: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16764448583126068, 0.9375]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\max_pooling2d_1\n",
      "......vars\n",
      "...layers\\max_pooling2d_2\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-18 23:08:41         3985\n",
      "metadata.json                                  2023-06-18 23:08:41           64\n",
      "variables.h5                                   2023-06-18 23:08:41     20381944\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finalized_40epoch_smile_detection_CNN_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# also loading \n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
