{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemention of LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "\tdef __init__(self, numPoints, radius):\n",
    "\t\tself.numPoints = numPoints\n",
    "\t\tself.radius = radius\n",
    "\tdef describe(self, image, eps=1e-7):\n",
    "\t\t# compute the Local Binary Pattern representation\n",
    "\t\t# of the image, and then use the LBP representation\n",
    "\t\t# to build the histogram of patterns\n",
    "\t\tlbp = feature.local_binary_pattern(image, self.numPoints,self.radius, method=\"uniform\")\n",
    "\t\t\n",
    "\t\t(hist, _) = np.histogram(lbp.ravel(),bins=np.arange(0, self.numPoints + 3),range=(0, self.numPoints + 2))\n",
    "\t\t\n",
    "\t\t# normalize the histogram\n",
    "\t\thist = hist.astype(\"float\")\n",
    "\t\thist /= (hist.sum() + eps)\n",
    "\n",
    "\t\treturn hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# x is feature of images, including HOG and LBP\n",
    "x = []\n",
    "# Make an instance of lbp class and set neighbour points and radius\n",
    "lbp_c = LocalBinaryPatterns(24, 2) # number of points, radius\n",
    "\n",
    "# start reading images one by one and do feature extraction\n",
    "for i in range(1,4001):\n",
    "    num = str(i).zfill(4)\n",
    "    img = cv2.imread('newimg/img'+ num +'.jpg')\n",
    "    img = cv2.resize(img, (100,100))\n",
    "\n",
    "    # required converts for HOG and LBP\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    hog_features = hog(img, orientations=30, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualize=False, channel_axis=-1) # HOG\n",
    "    lbp_features = lbp_c.describe(gray) # LBP\n",
    "\n",
    "    # Concatination of HOG and LBP and append into x array\n",
    "    x.append(np.concatenate((hog_features,lbp_features),axis = 0))\n",
    "\n",
    "# Read the label, the first column of the file\n",
    "y = pd.read_csv('labels.txt',' ',header=None)\n",
    "y = y.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the ML model, using SVC\n",
    "* importing SVC class\n",
    "* importing metrics for evaluation\n",
    "* train_test_split for seperate train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the SVC model\n",
    "Then Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel = 'linear', random_state = 13)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good accuracy with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  <bound method ClassifierMixin.score of SVC(kernel='linear', random_state=13)>\n",
      "Confusion Matrix = \n",
      "[[368  79]\n",
      " [ 98 455]]\n",
      "Accuracy =  0.823\n",
      "F1 =  0.8371665133394665\n",
      "Precision =  0.8520599250936329\n",
      "Recall =  0.8227848101265823\n"
     ]
    }
   ],
   "source": [
    "print('Score = ',classifier.score)\n",
    "print('Confusion Matrix = ')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy = ', accuracy_score(y_test, y_pred))\n",
    "print('F1 = ', f1_score(y_test, y_pred))\n",
    "print('Precision = ', precision_score(y_test, y_pred))\n",
    "print('Recall = ', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finalized_smile_detection_SVC_model.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    "\n",
    "# also loading \n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input your image\n",
    "* Read a image\n",
    "* Detect its face\n",
    "* Shows the detected face \n",
    "* Do feature extraction\n",
    "* Predict if it is smile or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Smiling! :) \n"
     ]
    }
   ],
   "source": [
    "# my image is in the folder with the name of photo.jpg\n",
    "inn = input()\n",
    "img = cv2.imread(inn)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "faces = face_cascade.detectMultiScale(gray, 1.2, 6)\n",
    "\n",
    "detected = 0\n",
    "if len(faces) != 1:\n",
    "    j = 1\n",
    "    while(len(faces) != 1):\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, j)\n",
    "        j+=1\n",
    "        if(len(faces) == 0):\n",
    "            break\n",
    "    if len(faces) != 1:\n",
    "        detected = 0\n",
    "    else:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        res = img[y:y+h,x: x+w]\n",
    "        detected = 1\n",
    "else:\n",
    "    (x, y, w, h) = faces[0]\n",
    "    res = img[y:y+h,x: x+w]\n",
    "    detected = 1\n",
    "\n",
    "cv2.imshow('image', res)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(detected)\n",
    "if detected:\n",
    "    res = cv2.resize(res, (100,100))\n",
    "    gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.cvtColor(res,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    hog_features = hog(img, orientations=30, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualize=False, channel_axis=-1) # HOG\n",
    "    lbp_features = lbp_c.describe(gray)\n",
    "\n",
    "    if classifier.predict([np.concatenate((hog_features,lbp_features),axis = 0)]):\n",
    "        print(\"Smiling! :) \")\n",
    "    else:\n",
    "        print(\"Not smiling! :(\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
